{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Drillhole Processing with gslib-zero\n",
    "\n",
    "This notebook covers drillhole data processing utilities:\n",
    "1. Minimum curvature desurvey\n",
    "2. Length-weighted compositing\n",
    "3. Interval table merging\n",
    "4. Integration with kriging workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from gslib_zero import (\n",
    "    desurvey, composite, merge_intervals,\n",
    "    nscore, gamv, kt3d,\n",
    "    GridSpec, VariogramModel, SearchParameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Create Sample Drillhole Data\n",
    "\n",
    "We'll create synthetic drillhole data with collar, survey, assay, and geology tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Collar table - 5 drillholes\n",
    "collar = pd.DataFrame({\n",
    "    'holeid': ['DH01', 'DH02', 'DH03', 'DH04', 'DH05'],\n",
    "    'x': [100.0, 200.0, 300.0, 150.0, 250.0],\n",
    "    'y': [100.0, 100.0, 100.0, 200.0, 200.0],\n",
    "    'z': [500.0, 510.0, 505.0, 495.0, 502.0],  # Surface elevation\n",
    "})\n",
    "\n",
    "print(\"Collar Table:\")\n",
    "collar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey table - measurements at intervals down the hole\n",
    "# Dip convention: negative = down (e.g., -60 = 60 degrees below horizontal)\n",
    "survey_records = []\n",
    "for hole in collar.holeid:\n",
    "    # Start vertical, gradually deviate\n",
    "    depths = [0, 25, 50, 75, 100, 125, 150]\n",
    "    for i, d in enumerate(depths):\n",
    "        azm = 90.0 + np.random.normal(0, 5)  # Roughly east, with drift\n",
    "        dip = -75.0 + i * 2 + np.random.normal(0, 2)  # Starts steep, flattens\n",
    "        survey_records.append({'holeid': hole, 'depth': d, 'azimuth': azm, 'dip': dip})\n",
    "\n",
    "survey = pd.DataFrame(survey_records)\n",
    "print(f\"Survey records: {len(survey)}\")\n",
    "survey.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assay table - grade samples at various intervals\n",
    "assay_records = []\n",
    "for hole in collar.holeid:\n",
    "    current = 0.0\n",
    "    while current < 140:\n",
    "        length = np.random.choice([1.0, 1.5, 2.0])  # Variable sample lengths\n",
    "        # Grade varies with depth and has spatial correlation\n",
    "        hole_idx = list(collar.holeid).index(hole)\n",
    "        base_grade = 1.5 + 0.01 * current + 0.005 * collar.x.iloc[hole_idx]\n",
    "        grade = base_grade + np.random.exponential(0.5)\n",
    "        assay_records.append({\n",
    "            'holeid': hole,\n",
    "            'from': current,\n",
    "            'to': current + length,\n",
    "            'au_ppm': grade\n",
    "        })\n",
    "        current += length\n",
    "\n",
    "assay = pd.DataFrame(assay_records)\n",
    "print(f\"Assay samples: {len(assay)}\")\n",
    "print(f\"Sample lengths: {(assay.to - assay['from']).unique()}\")\n",
    "assay.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geology table - rock type intervals\n",
    "geology_records = []\n",
    "for hole in collar.holeid:\n",
    "    # Simple geology: overburden -> oxide -> fresh\n",
    "    geology_records.extend([\n",
    "        {'holeid': hole, 'from': 0, 'to': 20, 'rocktype': 'OVB'},\n",
    "        {'holeid': hole, 'from': 20, 'to': 60, 'rocktype': 'OX'},\n",
    "        {'holeid': hole, 'from': 60, 'to': 150, 'rocktype': 'FR'},\n",
    "    ])\n",
    "\n",
    "geology = pd.DataFrame(geology_records)\n",
    "print(\"Geology Table:\")\n",
    "geology.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Minimum Curvature Desurvey\n",
    "\n",
    "Convert downhole depths to 3D coordinates using the minimum curvature method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desurvey at survey stations only\n",
    "survey_coords = desurvey(\n",
    "    collar=collar,\n",
    "    survey=survey,\n",
    ")\n",
    "\n",
    "print(f\"Survey coordinates: {len(survey_coords)}\")\n",
    "survey_coords.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desurvey at sample midpoints\n",
    "sample_coords = desurvey(\n",
    "    collar=collar,\n",
    "    survey=survey,\n",
    "    depths=assay,  # Compute at assay midpoints\n",
    ")\n",
    "\n",
    "print(f\"Sample coordinates: {len(sample_coords)}\")\n",
    "sample_coords.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize drillhole traces in 3D\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 5))\n",
    "\n",
    "for i, hole in enumerate(collar.holeid):\n",
    "    mask = survey_coords.holeid == hole\n",
    "    ax.plot(\n",
    "        survey_coords.x[mask],\n",
    "        survey_coords.y[mask],\n",
    "        survey_coords.z[mask],\n",
    "        'o-', color=colors[i], label=hole, markersize=3\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('X (Easting)')\n",
    "ax.set_ylabel('Y (Northing)')\n",
    "ax.set_zlabel('Z (Elevation)')\n",
    "ax.set_title('Drillhole Traces (Minimum Curvature Desurvey)')\n",
    "ax.legend()\n",
    "ax.view_init(elev=20, azim=-60)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Interval Merging\n",
    "\n",
    "Merge assay and geology tables to get rock type for each assay interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge assay and geology\n",
    "merged = merge_intervals(assay, geology)\n",
    "\n",
    "print(f\"Merged records: {len(merged)}\")\n",
    "print(f\"\\nColumns: {list(merged.columns)}\")\n",
    "merged.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that boundaries are split correctly\n",
    "hole1 = merged[merged.holeid == 'DH01'].copy()\n",
    "print(\"DH01 intervals near geology boundaries (depth 20 and 60):\")\n",
    "print(hole1[(hole1['from'] < 25) | ((hole1['from'] >= 55) & (hole1['from'] <= 65))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 4. Length-Weighted Compositing\n",
    "\n",
    "Create fixed-length composites, optionally breaking at domain boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple compositing without domain control\n",
    "comp_simple = composite(\n",
    "    merged,\n",
    "    length=5.0,\n",
    "    min_coverage=0.5,\n",
    "    columns=['au_ppm'],\n",
    ")\n",
    "\n",
    "print(f\"Simple composites: {len(comp_simple.data)}\")\n",
    "print(f\"Mean coverage: {comp_simple.coverage.mean():.2%}\")\n",
    "comp_simple.data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compositing with domain breaks\n",
    "comp_domain = composite(\n",
    "    merged,\n",
    "    length=5.0,\n",
    "    min_coverage=0.5,\n",
    "    columns=['au_ppm'],\n",
    "    domain_column='rocktype',\n",
    ")\n",
    "\n",
    "print(f\"Domain composites: {len(comp_domain.data)}\")\n",
    "print(f\"Mean coverage: {comp_domain.coverage.mean():.2%}\")\n",
    "\n",
    "# Show composites near domain boundary\n",
    "print(\"\\nComposites near depth 60 (OX/FR boundary):\")\n",
    "boundary_comps = comp_domain.data[\n",
    "    (comp_domain.data['from'] >= 55) & (comp_domain.data['to'] <= 70)\n",
    "]\n",
    "boundary_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs composited distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(merged.au_ppm, bins=30, alpha=0.7, label='Original')\n",
    "axes[0].hist(comp_domain.data.au_ppm, bins=30, alpha=0.7, label='Composited')\n",
    "axes[0].set_xlabel('Au (ppm)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Grade Distribution: Original vs Composited')\n",
    "axes[0].legend()\n",
    "\n",
    "# Sample lengths\n",
    "orig_lengths = merged['to'] - merged['from']\n",
    "comp_lengths = comp_domain.data['to'] - comp_domain.data['from']\n",
    "axes[1].hist(orig_lengths, bins=20, alpha=0.7, label='Original')\n",
    "axes[1].hist(comp_lengths, bins=20, alpha=0.7, label='Composited')\n",
    "axes[1].set_xlabel('Sample Length (m)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Sample Length Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Kriging\n",
    "\n",
    "Combine composites with 3D coordinates for estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3D coordinates at composite midpoints\n",
    "comp_coords = desurvey(\n",
    "    collar=collar,\n",
    "    survey=survey,\n",
    "    depths=comp_domain.data,\n",
    ")\n",
    "\n",
    "# Merge coordinates with composite grades\n",
    "# Match on holeid and depth (from desurvey output)\n",
    "composites_3d = comp_domain.data.copy()\n",
    "composites_3d['mid_depth'] = (composites_3d['from'] + composites_3d['to']) / 2\n",
    "\n",
    "# Add coordinates\n",
    "composites_3d = composites_3d.merge(\n",
    "    comp_coords,\n",
    "    left_on=['holeid', 'mid_depth'],\n",
    "    right_on=['holeid', 'depth'],\n",
    "    how='left'\n",
    ").drop(columns=['depth', 'mid_depth'])\n",
    "\n",
    "print(f\"Composites with 3D coordinates: {len(composites_3d)}\")\n",
    "composites_3d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to \"Fresh\" rock type for domain estimation\n",
    "fresh_data = composites_3d[composites_3d.rocktype == 'FR'].copy()\n",
    "print(f\"Fresh rock composites: {len(fresh_data)}\")\n",
    "print(f\"Grade range: {fresh_data.au_ppm.min():.2f} - {fresh_data.au_ppm.max():.2f}\")\n",
    "print(f\"Mean grade: {fresh_data.au_ppm.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal score transform\n",
    "fresh_data['nscore'], transform_table = nscore(fresh_data.au_ppm, binary=True)\n",
    "\n",
    "print(f\"Normal score mean: {fresh_data.nscore.mean():.4f}\")\n",
    "print(f\"Normal score std: {fresh_data.nscore.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 6. Variogram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute experimental variogram\n",
    "vario_result = gamv(\n",
    "    fresh_data.x, fresh_data.y, fresh_data.z, fresh_data.nscore,\n",
    "    nlag=10,\n",
    "    lag_distance=20.0,\n",
    "    binary=True\n",
    ")[0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(vario_result.lag_distances, vario_result.gamma, 'bo-', label='Experimental')\n",
    "plt.axhline(1.0, color='gray', linestyle='--', alpha=0.5, label='Sill = 1.0')\n",
    "plt.xlabel('Lag Distance (m)')\n",
    "plt.ylabel('Gamma')\n",
    "plt.title('Experimental Variogram - Fresh Rock Composites')\n",
    "plt.legend()\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit variogram model\n",
    "variogram = VariogramModel.spherical(\n",
    "    sill=0.8,\n",
    "    ranges=(80, 80, 40),  # Horizontal, horizontal, vertical\n",
    "    nugget=0.2\n",
    ")\n",
    "\n",
    "print(f\"Total sill: {variogram.total_sill}\")\n",
    "print(f\"Nugget: {variogram.nugget}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 7. Kriging Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid covering the data extent\n",
    "grid = GridSpec(\n",
    "    nx=20, ny=15, nz=10,\n",
    "    xmin=fresh_data.x.min() - 10,\n",
    "    ymin=fresh_data.y.min() - 10,\n",
    "    zmin=fresh_data.z.min() - 5,\n",
    "    xsiz=10, ysiz=10, zsiz=10,\n",
    ")\n",
    "\n",
    "print(f\"Grid cells: {grid.ncells}\")\n",
    "print(f\"X range: {grid.xmin:.0f} to {grid.xmax:.0f}\")\n",
    "print(f\"Y range: {grid.ymin:.0f} to {grid.ymax:.0f}\")\n",
    "print(f\"Z range: {grid.zmin:.0f} to {grid.zmax:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search parameters\n",
    "search = SearchParameters(\n",
    "    radius1=150,\n",
    "    radius2=150,\n",
    "    radius3=100,\n",
    "    min_samples=3,\n",
    "    max_samples=12,\n",
    ")\n",
    "\n",
    "# Run kriging - using DataFrame pattern\n",
    "result = kt3d(\n",
    "    data=fresh_data, value_col='nscore',\n",
    "    grid=grid, variogram=variogram, search=search,\n",
    "    kriging_type='ordinary',\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "print(f\"Estimate shape: {result.estimate.shape}\")\n",
    "print(f\"Valid estimates: {(result.estimate > -998).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a horizontal slice\n",
    "z_slice = 5  # Middle z-level\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Estimates\n",
    "estimate_slice = result.estimate[z_slice]\n",
    "estimate_slice[estimate_slice < -998] = np.nan  # Mask unestimated\n",
    "\n",
    "im1 = axes[0].imshow(\n",
    "    estimate_slice,\n",
    "    extent=[grid.xmin, grid.xmax, grid.ymin, grid.ymax],\n",
    "    origin='lower',\n",
    "    cmap='viridis'\n",
    ")\n",
    "# Show sample locations at this level\n",
    "z_center = grid.zmin + (z_slice + 0.5) * grid.zsiz\n",
    "near_z = fresh_data[abs(fresh_data.z - z_center) < grid.zsiz]\n",
    "axes[0].scatter(near_z.x, near_z.y, c='red', s=30, alpha=0.7, label='Samples')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "axes[0].set_title(f'Kriged Estimates (Z = {z_center:.0f})')\n",
    "axes[0].legend()\n",
    "plt.colorbar(im1, ax=axes[0], label='Normal Score')\n",
    "\n",
    "# Variance\n",
    "variance_slice = result.variance[z_slice]\n",
    "variance_slice[variance_slice < 0] = np.nan\n",
    "\n",
    "im2 = axes[1].imshow(\n",
    "    variance_slice,\n",
    "    extent=[grid.xmin, grid.xmax, grid.ymin, grid.ymax],\n",
    "    origin='lower',\n",
    "    cmap='Reds'\n",
    ")\n",
    "axes[1].scatter(near_z.x, near_z.y, c='blue', s=30, alpha=0.7, label='Samples')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "axes[1].set_title(f'Kriging Variance (Z = {z_center:.0f})')\n",
    "axes[1].legend()\n",
    "plt.colorbar(im2, ax=axes[1], label='Variance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the drillhole-to-estimate workflow:\n",
    "\n",
    "1. **Desurvey**: Convert downhole depths to 3D coordinates using minimum curvature\n",
    "2. **Merge intervals**: Combine assay and geology tables, splitting at boundaries\n",
    "3. **Composite**: Create fixed-length composites with domain control\n",
    "4. **Prepare for estimation**: Add 3D coordinates to composites, filter by domain\n",
    "5. **Variogram + Kriging**: Standard geostatistical workflow with the processed data\n",
    "\n",
    "Key functions used:\n",
    "- `desurvey()` - Minimum curvature 3D coordinate calculation\n",
    "- `merge_intervals()` - Combine multiple interval tables\n",
    "- `composite()` - Length-weighted compositing with domain breaks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
