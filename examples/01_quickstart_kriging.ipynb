{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gslib-zero Quickstart: From Data to Kriged Estimates\n",
    "\n",
    "This notebook walks through a complete geostatistical workflow:\n",
    "1. Load/create sample data\n",
    "2. Normal score transform\n",
    "3. Variogram analysis\n",
    "4. Kriging estimation\n",
    "5. Back-transform and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# gslib-zero imports\n",
    "from gslib_zero import (\n",
    "    nscore, backtr,\n",
    "    gamv, plot_variogram,\n",
    "    kt3d,\n",
    "    GridSpec, VariogramModel, SearchParameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Sample Data\n",
    "\n",
    "We'll create a synthetic dataset that mimics a typical mineral deposit with spatial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate 100 sample locations as a DataFrame\n",
    "n_samples = 100\n",
    "df = pd.DataFrame({\n",
    "    'x': np.random.uniform(0, 1000, n_samples),\n",
    "    'y': np.random.uniform(0, 1000, n_samples),\n",
    "    'z': np.zeros(n_samples),\n",
    "})\n",
    "\n",
    "# Generate spatially correlated values (trend + noise)\n",
    "trend = 0.005 * df.x + 0.003 * df.y\n",
    "noise = np.random.normal(0, 1.5, n_samples)\n",
    "df['grade'] = 5.0 + trend + noise\n",
    "\n",
    "print(f\"Samples: {len(df)}\")\n",
    "print(f\"Grade range: {df.grade.min():.2f} - {df.grade.max():.2f}\")\n",
    "print(f\"Mean: {df.grade.mean():.2f}, Std: {df.grade.std():.2f}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df.grade, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Grade')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Grade Distribution')\n",
    "axes[0].axvline(df.grade.mean(), color='red', linestyle='--', label=f'Mean: {df.grade.mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Sample locations colored by value\n",
    "scatter = axes[1].scatter(df.x, df.y, c=df.grade, cmap='viridis', s=50)\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "axes[1].set_title('Sample Locations')\n",
    "plt.colorbar(scatter, ax=axes[1], label='Grade')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normal Score Transform\n",
    "\n",
    "Many geostatistical methods assume Gaussian distributions. We transform to normal scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to normal scores - accepts Series directly!\n",
    "df['nscore'], transform_table = nscore(df.grade, binary=True)\n",
    "\n",
    "print(f\"Original mean: {df.grade.mean():.3f}\")\n",
    "print(f\"Normal score mean: {df.nscore.mean():.6f}\")  # Should be ~0\n",
    "print(f\"Normal score std: {df.nscore.std():.6f}\")    # Should be ~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the transform\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(df.grade, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Original Distribution')\n",
    "axes[0].set_xlabel('Grade')\n",
    "\n",
    "axes[1].hist(df.nscore, bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_title('Normal Score Distribution')\n",
    "axes[1].set_xlabel('Normal Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Variogram Analysis\n",
    "\n",
    "Compute experimental variogram to understand spatial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute omnidirectional variogram - pass Series directly\n",
    "variogram_results = gamv(\n",
    "    df.x, df.y, df.z, df.nscore,\n",
    "    nlag=15,\n",
    "    lag_distance=50.0,\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "# gamv returns a list (one per direction)\n",
    "variogram_result = variogram_results[0]\n",
    "print(f\"Lags computed: {len(variogram_result.gamma)}\")\n",
    "print(f\"Max lag distance: {variogram_result.lag_distances.max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit Variogram Model\n",
    "\n",
    "Manually fit a theoretical model to the experimental variogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spherical variogram model\n",
    "# Parameters chosen by examining the experimental variogram\n",
    "variogram_model = VariogramModel.spherical(\n",
    "    sill=0.85,\n",
    "    ranges=(300, 300, 1),\n",
    "    nugget=0.15\n",
    ")\n",
    "\n",
    "print(f\"Total sill: {variogram_model.total_sill}\")\n",
    "print(f\"Nugget: {variogram_model.nugget}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot experimental vs model\n",
    "ax = plot_variogram(\n",
    "    experimental=variogram_result,\n",
    "    model=variogram_model,\n",
    "    title=\"Variogram: Experimental vs Model\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Estimation Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSpec(\n",
    "    nx=50, ny=50, nz=1,\n",
    "    xmin=10, ymin=10, zmin=0,\n",
    "    xsiz=20, ysiz=20, zsiz=1\n",
    ")\n",
    "\n",
    "print(f\"Grid cells: {grid.ncells}\")\n",
    "print(f\"Grid extent: X({grid.xmin}-{grid.xmax}), Y({grid.ymin}-{grid.ymax})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Kriging\n",
    "\n",
    "Run ordinary kriging on normal scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search neighborhood\n",
    "search = SearchParameters(\n",
    "    radius1=400,\n",
    "    radius2=400,\n",
    "    radius3=10,\n",
    "    min_samples=4,\n",
    "    max_samples=16,\n",
    ")\n",
    "\n",
    "# Run kriging - pass Series directly!\n",
    "result = kt3d(\n",
    "    df.x, df.y, df.z, df.nscore,\n",
    "    grid, variogram_model, search,\n",
    "    kriging_type=\"ordinary\",\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "print(f\"Estimate shape: {result.estimate.shape}\")\n",
    "print(f\"Kriged mean (normal scores): {result.estimate.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: DataFrame with column names\n",
    "\n",
    "You can also pass the DataFrame directly with column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent using data= parameter\n",
    "result_alt = kt3d(\n",
    "    data=df, value_col='nscore',\n",
    "    grid=grid, variogram=variogram_model, search=search,\n",
    "    kriging_type=\"ordinary\",\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "# Results are identical\n",
    "print(f\"Results match: {np.allclose(result.estimate, result_alt.estimate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Back-Transform\n",
    "\n",
    "Convert kriged normal scores back to original units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_original = backtr(\n",
    "    result.estimate.ravel(),\n",
    "    transform_table,\n",
    "    zmin=df.grade.min() * 0.9,\n",
    "    zmax=df.grade.max() * 1.1,\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "estimates_original = estimates_original.reshape(result.estimate.shape)\n",
    "\n",
    "print(f\"Back-transformed mean: {estimates_original.mean():.2f}\")\n",
    "print(f\"Original data mean: {df.grade.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Kriged estimates\n",
    "im1 = axes[0].imshow(\n",
    "    estimates_original[0],\n",
    "    extent=[grid.xmin, grid.xmax, grid.ymin, grid.ymax],\n",
    "    origin='lower',\n",
    "    cmap='viridis'\n",
    ")\n",
    "axes[0].scatter(df.x, df.y, c='red', s=20, alpha=0.5, label='Samples')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "axes[0].set_title('Kriged Estimates')\n",
    "axes[0].legend()\n",
    "plt.colorbar(im1, ax=axes[0], label='Grade')\n",
    "\n",
    "# Kriging variance\n",
    "im2 = axes[1].imshow(\n",
    "    result.variance[0],\n",
    "    extent=[grid.xmin, grid.xmax, grid.ymin, grid.ymax],\n",
    "    origin='lower',\n",
    "    cmap='Reds'\n",
    ")\n",
    "axes[1].scatter(df.x, df.y, c='blue', s=20, alpha=0.5, label='Samples')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "axes[1].set_title('Kriging Variance (Uncertainty)')\n",
    "axes[1].legend()\n",
    "plt.colorbar(im2, ax=axes[1], label='Variance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Loading data as a pandas DataFrame\n",
    "- Passing Series directly to gslib-zero functions (no `.values` needed)\n",
    "- Complete workflow: nscore → gamv → kt3d → backtr\n",
    "- Both input patterns: `kt3d(df.x, df.y, ...)` and `kt3d(data=df, value_col=...)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
